# SR-LLM

Exploring Spatial Reasoning Abilities of LLMs. 

<img width="1230" alt="Screenshot 2025-03-19 at 23 28 35" src="https://github.com/user-attachments/assets/6571796d-94b2-4454-b2f9-c293b5acb856" />

This is my bachelor's thesis project. I answered following questions:
- Can LLMs understand 2D and 3D worlds?
- How can we measure the performance?
- How do we curate a dataset for this problem?
- What kind of prompting is optimal?
- What about fine-tunining a small language model?


## Notebooks

- [FineTuning Notebook (Colab)](https://colab.research.google.com/drive/1KU9aCMk-DjqGXH7EnaV1Q3wxR1G5fYA2)
- [Merging Adapter Notebook (Kaggle)](https://www.kaggle.com/code/arseniikvachan/sr-llm-merge-adapter-with-base-mistral)
- [GGUF Notebook (Kaggle)](https://www.kaggle.com/code/arseniikvachan/sr-llm-quantize-gguf-mistral)


